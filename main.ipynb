{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('/home/aistudio/external-libraries')\n",
    "\n",
    "from colossalai.legacy.amp import AMP_TYPE\n",
    "\n",
    "BATCH_SIZE = 256\n",
    "DROP_RANK = 0.1\n",
    "NUM_EPOCHS = 300\n",
    "\n",
    "fp16 = dict(\n",
    "    mode=AMP_TYPE.TORCH,\n",
    ")\n",
    "\n",
    "gradient_accumulation = 16\n",
    "clip_grad_norm = 1.0\n",
    "dail = dict(\n",
    "    gpu_aug=True,\n",
    "    mixup_alpha=0.2\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import colossalai\n",
    "from colossalai.legacy.context import ParallelMode\n",
    "from colossalai.legacy.core import global_context as gpc\n",
    "from colossalai.logging import disable_existing_loggers, get_dist_logger\n",
    "from colossalai.nn.lr_scheduler import LinearWarmupLR\n",
    "from colossalai.legacy.nn.metric import Accuracy\n",
    "from colossalai.legacy.trainer import Trainer, hooks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'timm'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mos\u001b[39;00m \n\u001b[1;32m      2\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mtorch\u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtimm\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mmodels\u001b[39;00m \u001b[39mimport\u001b[39;00m vit_base_patch16_224\n\u001b[1;32m      4\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtorchvision\u001b[39;00m \u001b[39mimport\u001b[39;00m tansforms\n\u001b[1;32m      5\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtrochvision\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mdatasets\u001b[39;00m \u001b[39mimport\u001b[39;00m CIFAR10\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'timm'"
     ]
    }
   ],
   "source": [
    "import os \n",
    "import torch\n",
    "from timm.models import vit_base_patch16_224\n",
    "from torchvision import tansforms\n",
    "from trochvision.datasets import CIFAR10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parser = colossalai.get_default_parser()\n",
    "args = parser.parse_args()\n",
    "colossalai.launch_from_torch(config=arg.config)\n",
    "disable_existing_loggers()\n",
    "logger = get_dist_logger()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(gpc.config.BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = vit_base_patch16_224(drop_rate=0.1, num_classes=gpc.config.NUM_CLASSES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_cifar(batch_size):\n",
    "    transform_train = transforms.Compose([\n",
    "        tansforms.RandomCrop(224, pad_if_needed=True),\n",
    "        transforms.AutoAugment(policy=transforms.AutoAugmentPolicy.CIFAR10),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize((0,4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
    "    ])\n",
    "    transform_test = transforms.Compose([\n",
    "        transforms.Resize(224),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize((0,4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
    "    ])\n",
    "    train_dataset = CIFAR10(root=os.environ['DATA'], train=True, download=True, transform=transform_train)\n",
    "    test_dataset = CIFAR10(root=os.environ['DATA'], train=False, transform=transform_test)\n",
    "    train_dataloader = get_dataloader(dataset=train_dataset, shuffle=True, batch_size=batch_size, pin_memory=True)\n",
    "    test_dataloader = get_dataloader(dataset=test_dataset, batch_size=batch_size, pin_memory=True)\n",
    "    return train_dataloader, test_dataloader\n",
    "\n",
    "train_dataloader, test_dataloader = build_cifar(gpc.config.BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = colossalai.nn.Lamb(model.parameters(), lr=1.8e-2, weight_decay=0.1)\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "lr_scheduler = LinearWarmupLR(optimizer, warmup_steps=50, total_steps=gpc.config.NUM_EPOCHS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "engine, train_dataloader, test_dataloader, _ = colossalai.initialize(model, optimizer, criterion, train_dataloader, test_dataloader)\n",
    "\n",
    "trainer = Trainer(engine=engine, logger=logger)\n",
    "hook_list = [\n",
    "    hooks.LossHook(),\n",
    "    hooks.AccuracyHook(accuracy_func=MixupAccuracy()),\n",
    "    hooks.LogMemoryByEpochHook(logger),\n",
    "    hooks.LRSchedulerHook(lr_scheduler, by_epoch=True),\n",
    "    hooks.SaveCheckpointHook(interval=1, checkpoint_dir='./ckpt'),\n",
    "    hooks.TensorboardHook(log_dir='./tb_logs', ranks=[0]),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.fit(\n",
    "    train_dataloader=train_dataloader,\n",
    "    test_dataloader=test_dataloader,\n",
    "    epochs=gpc.config.NUM_EPOCHS,\n",
    "    hooks=hook_list,\n",
    "    display_progress=True,\n",
    "    test_interval=1\n",
    ") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "export DATA=/home/aistudio/data\n",
    "torchrun --standalone --nproc_per_node=1 train_dp.py --config ./configs/config_data_parallel.py"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.10 ('python35-paddle120-env')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "09f0dbf7b1569c1ab842ae2f41770fe6aa1b54326d081112fa5944b99abb5899"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
